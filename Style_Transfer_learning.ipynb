{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled44.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4Q3+d6qeQHut59TN3guCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrakanta-chaudhury/Image-video-analysis/blob/master/Style_Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5qkzLwnLR8D"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from keras.applications import vgg16\n",
        "#from keras.applications import resnet50\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "def preprocess_image(image_path, height=None, width=None):\n",
        "    height = 400 if not height else height\n",
        "    width = width if width else int(width * height / height)\n",
        "    img = load_img(image_path, target_size=(height, width))\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = vgg16.preprocess_input(img)\n",
        "    return img\n",
        "\n",
        "def deprocess_image(x):\n",
        "    # Remove zero-center by mean pixel\n",
        "    x[:, :, 0] += 103.939\n",
        "    x[:, :, 1] += 116.779\n",
        "    x[:, :, 2] += 123.68\n",
        "    # 'BGR'->'RGB'\n",
        "    x = x[:, :, ::-1]\n",
        "    x = np.clip(x, 0, 255).astype('uint8')\n",
        "    return x"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fNSpkYkjuW0"
      },
      "source": [
        "\n",
        "# This is the path to the image you want to transform.\n",
        "TARGET_IMG = '/content/elon.jpg'\n",
        "# This is the path to the style image.\n",
        "REFERENCE_STYLE_IMG = '/content/india.jpg'\n",
        "\n",
        "width, height = load_img(TARGET_IMG).size\n",
        "img_height = 480\n",
        "img_width = int(width * img_height / height)\n",
        "\n",
        "\n",
        "target_image = K.constant(preprocess_image(TARGET_IMG, height=img_height, width=img_width))\n",
        "style_image = K.constant(preprocess_image(REFERENCE_STYLE_IMG, height=img_height, width=img_width))\n",
        "\n",
        "# Placeholder for our generated image\n",
        "generated_image = K.placeholder((1, img_height, img_width, 3))\n",
        "\n",
        "# Combine the 3 images into a single batch\n",
        "input_tensor = K.concatenate([target_image,\n",
        "                              style_image,\n",
        "                              generated_image], axis=0)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXVtuU51j6Bj"
      },
      "source": [
        "model = vgg16.VGG16(input_tensor=input_tensor,\n",
        "                    weights='imagenet',\n",
        "                    include_top=False)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq06bijQj_8H",
        "outputId": "3d8736c0-5fe1-417d-f74e-32967028992d"
      },
      "source": [
        "layers = {l.name: l.output for l in model.layers}\n",
        "layers"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'block1_conv1': <tf.Tensor 'block1_conv1_2/Relu:0' shape=(3, 480, 330, 64) dtype=float32>,\n",
              " 'block1_conv2': <tf.Tensor 'block1_conv2_2/Relu:0' shape=(3, 480, 330, 64) dtype=float32>,\n",
              " 'block1_pool': <tf.Tensor 'block1_pool_2/MaxPool:0' shape=(3, 240, 165, 64) dtype=float32>,\n",
              " 'block2_conv1': <tf.Tensor 'block2_conv1_2/Relu:0' shape=(3, 240, 165, 128) dtype=float32>,\n",
              " 'block2_conv2': <tf.Tensor 'block2_conv2_2/Relu:0' shape=(3, 240, 165, 128) dtype=float32>,\n",
              " 'block2_pool': <tf.Tensor 'block2_pool_2/MaxPool:0' shape=(3, 120, 82, 128) dtype=float32>,\n",
              " 'block3_conv1': <tf.Tensor 'block3_conv1_2/Relu:0' shape=(3, 120, 82, 256) dtype=float32>,\n",
              " 'block3_conv2': <tf.Tensor 'block3_conv2_2/Relu:0' shape=(3, 120, 82, 256) dtype=float32>,\n",
              " 'block3_conv3': <tf.Tensor 'block3_conv3_2/Relu:0' shape=(3, 120, 82, 256) dtype=float32>,\n",
              " 'block3_pool': <tf.Tensor 'block3_pool_2/MaxPool:0' shape=(3, 60, 41, 256) dtype=float32>,\n",
              " 'block4_conv1': <tf.Tensor 'block4_conv1_2/Relu:0' shape=(3, 60, 41, 512) dtype=float32>,\n",
              " 'block4_conv2': <tf.Tensor 'block4_conv2_2/Relu:0' shape=(3, 60, 41, 512) dtype=float32>,\n",
              " 'block4_conv3': <tf.Tensor 'block4_conv3_2/Relu:0' shape=(3, 60, 41, 512) dtype=float32>,\n",
              " 'block4_pool': <tf.Tensor 'block4_pool_2/MaxPool:0' shape=(3, 30, 20, 512) dtype=float32>,\n",
              " 'block5_conv1': <tf.Tensor 'block5_conv1_2/Relu:0' shape=(3, 30, 20, 512) dtype=float32>,\n",
              " 'block5_conv2': <tf.Tensor 'block5_conv2_2/Relu:0' shape=(3, 30, 20, 512) dtype=float32>,\n",
              " 'block5_conv3': <tf.Tensor 'block5_conv3_2/Relu:0' shape=(3, 30, 20, 512) dtype=float32>,\n",
              " 'block5_pool': <tf.Tensor 'block5_pool_2/MaxPool:0' shape=(3, 15, 10, 512) dtype=float32>,\n",
              " 'input_5': <tf.Tensor 'concat_5:0' shape=(3, 480, 330, 3) dtype=float32>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puK4NwmzkCnO"
      },
      "source": [
        "def content_loss(base, combination):\n",
        "    return K.sum(K.square(combination - base))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UvScBdTkFBI"
      },
      "source": [
        "def style_loss(style, combination, height, width):\n",
        "    \n",
        "    def build_gram_matrix(x):\n",
        "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "        gram_matrix = K.dot(features, K.transpose(features))\n",
        "        return gram_matrix\n",
        "\n",
        "    S = build_gram_matrix(style)\n",
        "    C = build_gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = height * width\n",
        "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1J8dw7LkIaT"
      },
      "source": [
        "def total_variation_loss(x):\n",
        "    a = K.square(\n",
        "        x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n",
        "    b = K.square(\n",
        "        x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n",
        "    return K.sum(K.pow(a + b, 1.25))"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpbcmrzYkK2i"
      },
      "source": [
        "content_weight = 0.05\n",
        "total_variation_weight = 1e-4\n",
        "\n",
        "\n",
        "content_layer = 'block4_conv2'\n",
        "style_layers = ['block{}_conv2'.format(o) for o in range(1,6)]\n",
        "style_weights = [0.1, 0.15, 0.2, 0.25, 0.3]\n",
        "\n",
        "# initialize total loss\n",
        "loss = K.variable(0.)\n",
        "\n",
        "# add content loss\n",
        "layer_features = layers[content_layer]\n",
        "target_image_features = layer_features[0, :, :, :]\n",
        "combination_features = layer_features[2, :, :, :]\n",
        "loss = loss + (content_weight * content_loss(target_image_features,\n",
        "                                      combination_features))\n",
        "\n",
        "# add style loss\n",
        "for layer_name, sw in zip(style_layers, style_weights):\n",
        "    layer_features = layers[layer_name]\n",
        "    style_reference_features = layer_features[1, :, :, :]\n",
        "    combination_features = layer_features[2, :, :, :]\n",
        "    sl = style_loss(style_reference_features, combination_features, \n",
        "                    height=img_height, width=img_width)\n",
        "    loss += (sl*sw)\n",
        "\n",
        "# add total variation loss\n",
        "loss += total_variation_weight * total_variation_loss(generated_image)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap1XfiZOkWEq"
      },
      "source": [
        "grads = K.gradients(loss, generated_image)[0]\n",
        "\n",
        "# Function to fetch the values of the current loss and the current gradients\n",
        "fetch_loss_and_grads = K.function([generated_image], [loss, grads])\n",
        "\n",
        "\n",
        "class Evaluator(object):\n",
        "\n",
        "    def __init__(self, height=None, width=None):\n",
        "        self.loss_value = None\n",
        "        self.grads_values = None\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "\n",
        "    def loss(self, x):\n",
        "        assert self.loss_value is None\n",
        "        x = x.reshape((1, self.height, self.width, 3))\n",
        "        outs = fetch_loss_and_grads([x])\n",
        "        loss_value = outs[0]\n",
        "        grad_values = outs[1].flatten().astype('float64')\n",
        "        self.loss_value = loss_value\n",
        "        self.grad_values = grad_values\n",
        "        return self.loss_value\n",
        "\n",
        "    def grads(self, x):\n",
        "        assert self.loss_value is not None\n",
        "        grad_values = np.copy(self.grad_values)\n",
        "        self.loss_value = None\n",
        "        self.grad_values = None\n",
        "        return grad_values\n",
        "\n",
        "evaluator = Evaluator(height=img_height, width=img_width)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IdMD_vyk56g",
        "outputId": "293232a0-3fdf-4b9b-9b3b-997d0bd9db0c"
      },
      "source": [
        "from scipy.optimize import fmin_l_bfgs_b\n",
        "from scipy.misc import imsave\n",
        "from imageio import imwrite\n",
        "import time\n",
        "\n",
        "result_prefix = 'st_res1_'\n",
        "iterations = 20\n",
        "\n",
        "# Run scipy-based optimization (L-BFGS) over the pixels of the generated image\n",
        "# so as to minimize the neural style loss.\n",
        "# This is our initial state: the target image.\n",
        "# Note that `scipy.optimize.fmin_l_bfgs_b` can only process flat vectors.\n",
        "x = preprocess_image(TARGET_IMG, height=img_height, width=img_width)\n",
        "x = x.flatten()\n",
        "\n",
        "for i in range(iterations):\n",
        "    print('Start of iteration', (i+1))\n",
        "    start_time = time.time()\n",
        "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x,\n",
        "                                     fprime=evaluator.grads, maxfun=20)\n",
        "    print('Current loss value:', min_val)\n",
        "    if (i+1) % 5 == 0 or i == 0:\n",
        "        # Save current generated image only every 5 iterations\n",
        "        img = x.copy().reshape((img_height, img_width, 3))\n",
        "        img = deprocess_image(img)\n",
        "        fname = result_prefix + '_iter%d.png' %(i+1)\n",
        "        imwrite(fname, img)\n",
        "        print('Image saved as', fname)\n",
        "    end_time = time.time()\n",
        "    print('Iteration %d completed in %ds' % (i+1, end_time - start_time))\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of iteration 1\n",
            "Current loss value: 33557420000.0\n",
            "Image saved as st_res1__iter1.png\n",
            "Iteration 1 completed in 14s\n",
            "Start of iteration 2\n",
            "Current loss value: 14130270000.0\n",
            "Iteration 2 completed in 8s\n",
            "Start of iteration 3\n",
            "Current loss value: 8615314000.0\n",
            "Iteration 3 completed in 9s\n",
            "Start of iteration 4\n",
            "Current loss value: 6493449000.0\n",
            "Iteration 4 completed in 9s\n",
            "Start of iteration 5\n",
            "Current loss value: 5336054000.0\n",
            "Image saved as st_res1__iter5.png\n",
            "Iteration 5 completed in 9s\n",
            "Start of iteration 6\n",
            "Current loss value: 4763984000.0\n",
            "Iteration 6 completed in 9s\n",
            "Start of iteration 7\n",
            "Current loss value: 4425908000.0\n",
            "Iteration 7 completed in 9s\n",
            "Start of iteration 8\n",
            "Current loss value: 4206725400.0\n",
            "Iteration 8 completed in 9s\n",
            "Start of iteration 9\n",
            "Current loss value: 4051254500.0\n",
            "Iteration 9 completed in 9s\n",
            "Start of iteration 10\n",
            "Current loss value: 3934059800.0\n",
            "Image saved as st_res1__iter10.png\n",
            "Iteration 10 completed in 9s\n",
            "Start of iteration 11\n",
            "Current loss value: 3835507700.0\n",
            "Iteration 11 completed in 9s\n",
            "Start of iteration 12\n",
            "Current loss value: 3753222100.0\n",
            "Iteration 12 completed in 9s\n",
            "Start of iteration 13\n",
            "Current loss value: 3686630400.0\n",
            "Iteration 13 completed in 9s\n",
            "Start of iteration 14\n",
            "Current loss value: 3626608600.0\n",
            "Iteration 14 completed in 9s\n",
            "Start of iteration 15\n",
            "Current loss value: 3574032100.0\n",
            "Image saved as st_res1__iter15.png\n",
            "Iteration 15 completed in 9s\n",
            "Start of iteration 16\n",
            "Current loss value: 3530272000.0\n",
            "Iteration 16 completed in 9s\n",
            "Start of iteration 17\n",
            "Current loss value: 3490904800.0\n",
            "Iteration 17 completed in 9s\n",
            "Start of iteration 18\n",
            "Current loss value: 3456444400.0\n",
            "Iteration 18 completed in 9s\n",
            "Start of iteration 19\n",
            "Current loss value: 3425941500.0\n",
            "Iteration 19 completed in 9s\n",
            "Start of iteration 20\n",
            "Current loss value: 3399084500.0\n",
            "Image saved as st_res1__iter20.png\n",
            "Iteration 20 completed in 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seJ6Ft23lwli"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}